#STEP 1
#build it
sudo docker build -t deepfakebench -f Dockerfile_3modern .

STEP 1.1
pip install albumentations==1.1.0

#STEP 2
#Run the Docker Image with standard volume mapping
#sudo docker run -itd -v /home/alex/Documents/DEV/2026_01_03_DEEPFAKEBENCH/DeepfakeBench/:/app/ --shm-size 64G deepfakebench
sudo docker run -itd -v /home/alex/Desktop/DEV/2026_01_04_CVDEEPFAKEBENCH/CVDeepfakeBench/:/app/ --shm-size 64G deepfakebench

sudo docker run -itd \
  -v /home/alex/Desktop/DEV/2026_01_04_CVDEEPFAKEBENCH/CVDeepfakeBench/:/app/ \
  -v /media/alex/Marcus:/media/alex/Marcus \
  --shm-size 64G \
  deepfakebench

#STEP 3
#Enter Docker Container
#sudo docker exec -it cranky_kare /bin/bash
#sudo docker exec -it stupefied_pascal /bin/bash
sudo docker exec -it zen_wescoff /bin/bash

#STEP 3.1
#Add ./training/weights/xception_best.pth
#Add ./preprocessing/dlib_tools/shape_predictor_81_face_landmarks.dat

#Add folders and dump data here or redirect to dataroot
./datasets/rgb
./datasets/lmdb 

#preprocess - 
python preprocess.py
python rearrange.py

#dataset_size does not necessarily allocate this out of the gate but it does set a ceiling on the memroy map
python dataset2lmdb_test.py --dataset_size 40
python dataset2lmdb_test_3.py --dataset_size 40
#success with 6 it created the stable lmdb out of Celeb-DF-v1 we think
python dataset2lmdb_test_6.py --dataset_size 40


#drop xception pretrained into the /training/pretrained folder

#troubleshooting this test command
#python3 training/test.py --detector_path ./training/config/detector/xception.yaml --test_dataset "Celeb-DF-v1" "Celeb-DF-v2" "DFDCP" --weights_path ./training/weights/xception_best.pth

#Success iwith xception
CUDA_VISIBLE_DEVICES="" python3 training/test.py --detector_path ./training/config/detector/xception.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/xception_best.pth

python3 training/test.py --detector_path ./training/config/detector/efficientnetb4.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/effnb4_best.pth

python3 training/test.py --detector_path ./training/config/detector/meso4.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/meso4_best.pth

python3 training/test.py --detector_path ./training/config/detector/meso4Inception.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/meso4Incep_best.pth

python3 training/test.py --detector_path ./training/config/detector/capsule_net.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/capsule_best.pth

#RUN 6 - FWA
python3 training/test.py --detector_path ./training/config/detector/fwa.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/xception_best.pth

#RUN 7 - TESTING the Weights_path change from xception to capsule -- hypotheiss confirmed, the weight path does need to point to the appropriately trained model to alignw ith the .yaml
python3 training/test.py --detector_path ./training/config/detector/fwa.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/capsule_best.pth

[SKIP]#RUN 8 - XRAY
python3 training/test.py --detector_path ./training/config/detector/facexray.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/capsule_best.pth

#RUN 9 - FFD
python3 training/test.py --detector_path ./training/config/detector/ffd.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/ffd_best.pth

#RUN 10 - Core
python3 training/test.py --detector_path ./training/config/detector/core.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/core_best.pth

#RUN 11 - Recce
python3 training/test.py --detector_path ./training/config/detector/recce.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/recce_best.pth

[NOPE]#RUN 12 - UCF
python3 training/test.py --detector_path ./training/config/detector/ucf.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/ucf_best.pth

#RUN 13 - F3NET
python3 training/test.py --detector_path ./training/config/detector/f3net.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/f3net_best.pth

#RUN 14 - SPSL
python3 training/test.py --detector_path ./training/config/detector/spsl.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/spsl_best.pth

#RUN 15 - SRM
python3 training/test.py --detector_path ./training/config/detector/srm.yaml --test_dataset "Celeb-DF-v1" --weights_path ./training/weights/srm_best.pth



#fixed the no run on GPU here
/app/training/dataset/lsda_dataset.py

#download CelebDF1

----

ON Kahunda cluster after successful lmdb.. to fix the dtype bug with imgaug
Open this file in VS Code: /home/asabbat/DEV/2026_01_08_CVDFD/venv/lib/python3.12/site-packages/imgaug/imgaug.py
replae at line 45 NP_FLOAT_TYPES = set(np.sctypes["float"])
NP_FLOAT_TYPES = {np.float16, np.float32, np.float64}
UPDATE - relac ehte 3lines in total with this
# NEW CODE (Fixed for NumPy 2.0)
NP_FLOAT_TYPES = {np.float16, np.float32, np.float64}
NP_INT_TYPES = {np.int8, np.int16, np.int32, np.int64}
NP_UINT_TYPES = {np.uint8, np.uint16, np.uint32, np.uint64}

WORKS!!!!
remember run when you get on a glidna node
module load cuda